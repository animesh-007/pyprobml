{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv2d-torch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkK1U1liTixqaVaxCyigAb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python367jvsc74a57bd050da0f6fa72fb86d21724871d314354b884db45bd357078f1680189ca335f685",
      "display_name": "Python 3.6.7 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.7-final"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "dfc3641d2968f953b738b1dc0c9747e3c41396f999ba0376896eb7547ee9da03"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/conv2d_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1BilhRQhLSv"
      },
      "source": [
        "# Foundations of Convolutional neural nets\n",
        "Based on sec 6.2 of\n",
        "http://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37BSsAk_hEZI"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(seed=1)\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "!mkdir figures # for saving plots\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj6qHIeFhmaB"
      },
      "source": [
        "# Cross correlation \n",
        "\n",
        "<img src=\"https://github.com/probml/pyprobml/blob/master/images/d2l-correlation.png?raw=true\" height=200>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V37sTMtzhUEH",
        "outputId": "5d9d95c8-c9e7-48f3-cfe0-1cf325e8cf79"
      },
      "source": [
        "# Cross correlation\n",
        "\n",
        "def corr2d(X, K):  #@save\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y\n",
        "\n",
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "print(corr2d(X, K))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[19., 25.],\n        [37., 43.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih0vOzPshqZo"
      },
      "source": [
        "# Edge detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl2lJFBahsaR"
      },
      "source": [
        "We make a small image X of 1s, with a vertical stripe (of width 4) of 0s in the middle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irYSam83hcEE",
        "outputId": "1552529b-ac0b-4d3b-c874-ec789477dc27"
      },
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "863GoP0Ph3k0"
      },
      "source": [
        "Now we apply a vertical edge detector. It fires on the 1-0 and 0-1 boundaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCG4tYnxh5l1",
        "outputId": "f895f8b5-e9f2-4ee5-be11-df60b023ea58"
      },
      "source": [
        "K = torch.tensor([[1.0, -1.0]])\n",
        "Y = corr2d(X, K)\n",
        "print(Y)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pwo2mn2iENa"
      },
      "source": [
        "It fails to detect horizontal edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W6VahQah8ol",
        "outputId": "fb2190fc-6d34-42d0-f50b-1f38c81eb777"
      },
      "source": [
        "corr2d(X.t(), K)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAktYXtl6ccn"
      },
      "source": [
        "# Convolution as matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tavm4P4w6g5c",
        "outputId": "e8018344-e181-46e7-93e4-5ba593fd54dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "#K = torch.tensor([[0, 1], [2, 3]])\n",
        "K = torch.tensor([[1,2], [3, 4]])\n",
        "\n",
        "print(K)\n",
        "\n",
        "def kernel2matrix(K):\n",
        "    k, W = torch.zeros(5), torch.zeros((4, 9))\n",
        "    k[:2], k[3:5] = K[0, :], K[1, :]\n",
        "    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k\n",
        "    return W\n",
        "\n",
        "W = kernel2matrix(K)\n",
        "print(W)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n        [3, 4]])\ntensor([[1., 2., 0., 3., 4., 0., 0., 0., 0.],\n        [0., 1., 2., 0., 3., 4., 0., 0., 0.],\n        [0., 0., 0., 1., 2., 0., 3., 4., 0.],\n        [0., 0., 0., 0., 1., 2., 0., 3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVNXaA8_6jJy",
        "outputId": "6b305ff7-42fa-447d-e78e-5eea85f196a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "X = torch.arange(9.0).reshape(3, 3)\n",
        "Y = corr2d(X, K)\n",
        "print(Y)\n",
        "\n",
        "Y2 = torch.mv(W, X.reshape(-1)).reshape(2, 2)\n",
        "assert np.allclose(Y, Y2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 37.],\n        [57., 67.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yhq_TwCiMy5"
      },
      "source": [
        "# Optimizing the kernel parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPRFUokDiPT7"
      },
      "source": [
        "Let's learn a kernel to match the output  of our manual edge detector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvFbhb9liU-t",
        "outputId": "adc80ac6-fb74-4f75-db55-6b389948563f"
      },
      "source": [
        "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
        "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
        "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "# The two-dimensional convolutional layer uses four-dimensional input and\n",
        "# output in the format of (example channel, height, width), where the batch\n",
        "# size (number of examples in the batch) and the number of channels are both 1\n",
        "# Defining X and Y again.\n",
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "\n",
        "K = torch.tensor([[1.0, -1.0]])\n",
        "Y = corr2d(X, K)\n",
        "\n",
        "X = X.reshape((1, 1, 6, 8))\n",
        "Y = Y.reshape((1, 1, 6, 7))\n",
        "\n",
        "for i in range(10):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y)**2\n",
        "    conv2d.zero_grad()\n",
        "    l.sum().backward()\n",
        "    # Update the kernel\n",
        "    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n",
        "    if (i + 1) % 2 == 0:\n",
        "        print(f'batch {i + 1}, loss {l.sum():.3f}')\n",
        "\n",
        "print(conv2d.weight.data.reshape((1, 2)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 2, loss 5.685\nbatch 4, loss 1.309\nbatch 6, loss 0.365\nbatch 8, loss 0.121\nbatch 10, loss 0.045\ntensor([[ 1.0103, -0.9683]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnNn2XHPiZqd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTNJUuYn27Kv"
      },
      "source": [
        "# Multiple input channels\n",
        "\n",
        "<img src=\"https://github.com/probml/pyprobml/blob/master/images/d2l-conv-multi-in.png?raw=true\" height=200>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def corr2d(X, K):\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = torch.sum((X[i:i + h, j:j + w] * K))\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlz4Um7b28iM",
        "outputId": "574a1d85-ebf4-44e1-d503-cd0458108593"
      },
      "source": [
        "def corr2d_multi_in(X, K):\n",
        "    # First, iterate through the 0th dimension (channel dimension) of `X` and\n",
        "    # `K`. Then, add them together\n",
        "    return sum(corr2d(x, k) for x, k in zip(X, K))\n",
        "\n",
        "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "\n",
        "print(X.shape) # 2 channels, each 3x3\n",
        "print(K.shape) # 2 sets of 2x2 filters\n",
        "out = corr2d_multi_in(X, K)\n",
        "print(out.shape)\n",
        "print(out)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 3])\ntorch.Size([2, 2, 2])\ntorch.Size([2, 2])\ntensor([[ 56.,  72.],\n        [104., 120.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6FlFthE47Zy"
      },
      "source": [
        "# Multiple output channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYIeq6s13FHf",
        "outputId": "8b80b6ce-88ad-4d88-9810-5faee0162d2c"
      },
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "    # Iterate through the 0th dimension of `K`, and each time, perform\n",
        "    # cross-correlation operations with input `X`. All of the results are\n",
        "    # stacked together\n",
        "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
        "\n",
        "K = torch.stack((K, K + 1, K + 2), 0)\n",
        "print(K.shape)\n",
        "out = corr2d_multi_in_out(X, K)\n",
        "print(out.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2, 2, 2])\ntorch.Size([3, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J55ZIGJR5rZK"
      },
      "source": [
        "# 1x1 convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ID1SeI55EaU",
        "outputId": "53bfceb5-ef6d-45da-9278-4459016eb83b"
      },
      "source": [
        "# 1x1 conv is same as multiplying each feature column at each pixel\n",
        "# by a fully connected matrix\n",
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = X.reshape((c_i, h * w))\n",
        "    K = K.reshape((c_o, c_i))\n",
        "    Y = torch.matmul(K,\n",
        "                     X)  # Matrix multiplication in the fully-connected layer\n",
        "    return Y.reshape((c_o, h, w))\n",
        "\n",
        "X = torch.normal(0, 1, (3, 3, 3)) # 3 channels per pixel\n",
        "K = torch.normal(0, 1, (2, 3, 1, 1)) # map from 3 channels to 2\n",
        "\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "print(Y2.shape)\n",
        "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZOVZR4R6xEB"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgoSzfYo6x74"
      },
      "source": [
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j] = X[i:i + p_h, j:j + p_w].max()\n",
        "            elif mode == 'avg':\n",
        "                Y[i, j] = X[i:i + p_h, j:j + p_w].mean()\n",
        "    return Y\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7QLazAI62na",
        "outputId": "2833323f-649b-4898-fd1c-f91d12bf75ce"
      },
      "source": [
        "#X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "X = torch.arange(16, dtype=torch.float32).reshape((4, 4))\n",
        "print(X)\n",
        "print(X.shape)\n",
        "print(pool2d(X, (3, 3), 'max'))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]])\ntorch.Size([4, 4])\ntensor([[10., 11.],\n        [14., 15.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naun3ed-6_H_",
        "outputId": "d01097e3-cad6-4652-e489-a4b92d52fa0e"
      },
      "source": [
        "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "pool2d = nn.MaxPool2d(3, padding=0, stride=1)\n",
        "print(pool2d(X))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[10., 11.],\n          [14., 15.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}